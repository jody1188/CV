# Jody

## Hong Jong Hyun

### ğŸ›  Tech
- <img src="https://img.shields.io/badge/Python-111111?style=flat&logo=Python&logoColor=white"/> <img src="https://img.shields.io/badge/Pytorch-EE4C2C?style=flat&logo=Pytorch&logoColor=white"/> <img src="https://img.shields.io/badge/SQL-4479A1?style=flat&logo=MySQL&logoColor=white"/> <img src="https://img.shields.io/badge/JavaScript-F7DF1E?style=flat&logo=JavaScript&logoColor=white"/> <img src="https://img.shields.io/badge/Git-F05032?style=flat&logo=Git&logoColor=white"/> <img src="https://img.shields.io/badge/Tableau-E97627?style=flat&logo=Tableau&logoColor=white"/> <img src="https://img.shields.io/badge/Docker-2496ED?style=flat&logo=Docker&logoColor=white"/> <img src="https://img.shields.io/badge/Conda-44A833?style=flat&logo=Anaconda&logoColor=white"/> <img src="https://img.shields.io/badge/Excel-217346?style=flat&logo=MicrosoftExcel&logoColor=white"/>
- <img src="https://img.shields.io/badge/Github-181717?style=flat&logo=Github&logoColor=white"/> <img src="https://img.shields.io/badge/Teams-6264A7?style=flat&logo=MicrosoftTeams&logoColor=white"/> <img src="https://img.shields.io/badge/Slack-4A154B?style=flat&logo=Slack&logoColor=white"/> <img src="https://img.shields.io/badge/Notion-000000?style=flat&logo=Notion&logoColor=white"/>

- <img src="https://img.shields.io/badge/Window-0078D6?style=flat&logo=Windows&logoColor=white"/> <img src="https://img.shields.io/badge/Mac-000000?style=flat&logo=Macos&logoColor=white"/> <img src="https://img.shields.io/badge/Linux-FCC624?style=flat&logo=Linux&logoColor=white"/>




### ğŸ“ Education
|ê¸°ê°„|ì†Œì†|ì „ê³µ|í•™ìœ„|ë¹„ê³ |
|-|-|-|-|-|
|2019.03~|êµ­ë¯¼ëŒ€í•™êµ|AIë¹…ë°ì´í„°ìœµí•©ê²½ì˜í•™ê³¼|ì‹¬í™”ì „ê³µ|ì¬í•™|
|2021.06~~2021.12|D&A|ë¹…ë°ì´í„° í•™íšŒ(ML)|ë©¤ë²„|ìˆ˜ë£Œ|
|2022.01~~2022.12|ToBig's|ë¹…ë°ì´í„° ì—°í•©ë™ì•„ë¦¬|17ê¸°|ìˆ˜ë£Œ|
|2023.03~|ì¤‘ì•™ëŒ€í•™êµ IIPLì—°êµ¬ì‹¤|ì¸ê³µì§€ëŠ¥ ì—°êµ¬|í•™ë¶€ì—°êµ¬ìƒ|ì§„í–‰ì¤‘|





### ğŸ’» Project
|ì—°ë„|ë¶„ë¥˜|í”„ë¡œì íŠ¸|ë¹„ê³ |
|-|-|-|-|
|2023|NLP|Local & Global Attentionì„ í™œìš©í•œ Transformer ê²½ëŸ‰í™”|ì—°êµ¬ì¤‘|
|2022|CV|MobileViTì™€ ì „ì´í•™ìŠµì„ í™œìš©í•œ ì‚¬ëŒ ìì„¸ ì¶”ì • ì•Œê³ ë¦¬ì¦˜ì˜ ê²½ëŸ‰í™”|ë…¼ë¬¸ ì‘ì„±ì¤‘|
|2022|NLP|SeqGANì„ í™œìš©í•œ ë©œë¡œë”” ê¸°ë°˜ í•œêµ­ì–´ ê°€ì‚¬ ìƒì„±|ë…¼ë¬¸ íˆ¬ê³ |
|2022|ìŒì„±|ZeroShot Learningê³¼ TTSë¥¼ í™œìš©í•œ ìŒì„± í•©ì„±|[ë§í¬](https://github.com/jody1188/ZtarGAN-VC)|
|2022|NLP|í‚¤ì›Œë“œì˜ êµ°ì§‘í™”ë¥¼ í†µí•œ ì†Œë¹„ì ë¦¬ë·° ë¶„ì„||
|2022|NLP|ì˜ì–´ ì»¨í…ì¸ ë¥¼ ì œì£¼ì˜ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ì—¬ ì§ì ‘ ì½ì–´ì£¼ëŠ” ì„œë¹„ìŠ¤|[ë§í¬](https://github.com/jody1188/jeju-blues)|
|2022|NLP|ì‚°ì—…ë¶„ë¥˜ ìë™í™” ì¸ê³µì§€ëŠ¥ ëª¨ë¸ ê°œë°œ||
|2021|ë¨¸ì‹ ëŸ¬ë‹|ì„¤ë¬¸ì¡°ì‚¬ ì‘ë‹µ ì—¬ë¶€ ì˜ˆì¸¡|[ë§í¬](https://github.com/jody1188/KML)|
|2021|ë¨¸ì‹ ëŸ¬ë‹|ì˜¨ë¼ì¸ í–‰ë™ ë° ìƒí’ˆ ë¶„ë¥˜ ë°ì´í„°ë¥¼ í™œìš©í•œ ì„±ë³„/ë‚˜ì´ëŒ€ ì˜ˆì¸¡|[ë§í¬](https://github.com/jody1188/L.Point)|



### ğŸ“š Paper review


| ì œëª© | ë§í¬ | 
| :------: | :------: |
|Transformer-XL : Attentive Language Models Beyond a Fixed-Length Context|[ë§í¬](https://velog.io/@jody1188/Transformer-XL-Attentive-Language-Models-Beyond-a-Fixed-Length-Context)|
|MobileViT - Version 1, 2|[ë§í¬](https://velog.io/@jody1188/MobileViT-Version-1-2)|
|Vision Transformer & ViTPose|[ë§í¬](https://velog.io/@jody1188/Vision-Transformer-VITPose)|
|DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRF|[ë§í¬](https://velog.io/@jody1188/DeepLab-Semantic-Image-Segmentation-with-Deep-Convolutional-Nets-Atrous-Convolution-and-Fully-Connected-CRF)|
|Object Tracking + Simple Online and Realtime Tracking : SORT|[ë§í¬](https://velog.io/@jody1188/Object-Tracking-Simple-Online-and-Realtime-Tracking-SORT)|
|Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks|[ë§í¬](https://velog.io/@jody1188/Unpaired-Image-to-Image-Translation-using-Cycle-Consistent-Adversarial-Networks)|
|TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning|[ë§í¬](https://velog.io/@jody1188/TSDAE-Using-Transformer-based-Sequential-Denoising-Auto-Encoder-for-Unsupervised-Sentence-Embedding-Learning)|
|DiffCSE: Difference-based Contrastive Learning for Sentence Embeddings|[ë§í¬](https://velog.io/@jody1188/DiffCSE-Difference-based-Contrastive-Learning-for-SentenceEmbeddings)|
|SimCSE : Simple Contrastive Learning of Sentence Embeddings|[ë§í¬](https://velog.io/@jody1188/SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings)|
|MUSIC COMPOSITION WITH DEEP LEARNING : A REVIEW|[ë§í¬](https://velog.io/@jody1188/MUSIC-COMPOSITION-WITH-DEEP-LEARNING)|
|Get To The Point : Summarization with Pointer-Generator Network's|[ë§í¬](https://velog.io/@jody1188/Get-To-The-Point-Summarization-with-Pointer-Generator-Networks)|
|Positional Encoding|[ë§í¬](https://velog.io/@jody1188/Positional-Encoding)|
|ALBERT: A Lite BERT for Self-supervised Learning of Language Representations|[ë§í¬](https://velog.io/@jody1188/ALBERT-A-Lite-BERT-for-Self-supervised-Learning-of-Language-Representations-6nvuc1sp)|
|BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding|[ë§í¬](https://velog.io/@jody1188/Transformer)|
|Attention is All You Need|[ë§í¬](https://velog.io/@jody1188/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding)|
|Sequence to Sequence with Attention|[ë§í¬](https://velog.io/@jody1188/Sequence-to-Sequence-with-Attention)|
|FastText - Enriching Word Vectors with Subword Information|[ë§í¬](https://velog.io/@jody1188/FastText-Enriching-Word-Vectors-with-Subword-Information)|
|Backpropagation Through Time|[ë§í¬](https://velog.io/@jody1188/BPTT)|
|GAN - Generative Adversarial Nets|[ë§í¬](https://velog.io/@jody1188/GAN-Generative-Adversarial-Nets)|
|ResNet - Deep Residual Learning for Image Recognition|[ë§í¬](https://velog.io/@jody1188/ResNet-Deep-Residual-Learning-for-Image-Recognition)|
|ELECTRA : Pre-training Text Encoders As Discriminators Rather than Generators|[ë§í¬](https://velog.io/@jody1188/ELECTRA-Pre-training-Text-Encoders-As-Discriminators-Rather-than-Generators)|
|GPT2 - Language Models are Unsupervised Multitask Learners|[ë§í¬](https://velog.io/@jody1188/GPT2-Language-Models-are-Unsupervised-Multitask-Learners)|
|GPT : Improving Language Understanding by Generative Pre-training|[ë§í¬](https://velog.io/@jody1188/GPT)|


### ğŸ“š Study review
| ì œëª© | ë§í¬ | 
| :------: | :------: |
|Linear Algebra|[ë§í¬](https://velog.io/@jody1188/series/Linear-Algebra)|
|CS224n|[ë§í¬](https://velog.io/@jody1188/series/CS224N)|
|DSP Basic|[ë§í¬](https://velog.io/@jody1188/1.-DSP-Basic)|
|Tensor Manipulation|[ë§í¬](https://velog.io/@jody1188/Tensor-Manipulation)|
